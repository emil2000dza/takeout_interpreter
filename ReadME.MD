# Digital Footprint Analysis

![Browsing History Overview](img/takeout.gif)

This project explores my **digital footprint**, focusing on Google Chrome browsing activity on mobile. Since most of my online activity is concentrated on Chrome, we use Google Takeout data to analyze, transform, and classify browsing behavior into broader topics using **LLMs**.

The goal of this project is to provide visualization examples and scripts for exploring an individual's digital footprint using their Google Takeout data. It combines Snowflake, dbt, and Metabase with a topic modeling pipeline that maps each visited URL to broader browsing activity topics.
- **Snowflake** â€“ Data warehouse for storage and querying  
- **GCS** â€“ Hosting raw and processed data  
- **Metabase** â€“ Visualization and exploration of results  

Parsers are also available for other Takeout data (YouTube, phone history, etc.).

---

## âš™ï¸ Prerequisites

- Docker installed on your system  
- `.env` file containing:  
  - Snowflake account parameters  
  - Gemini API Key  

> A template `.env.example` is provided; it must be updated with your own credentials.

---

## ğŸ“ Project Structure
```google_takeout_analyser/
â”œâ”€â”€ data/                     # Your Takeout data
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parsers/              # Scripts to parse Takeout data into CSV
â”‚   â”œâ”€â”€ topic_modeling/       # Topic modeling pipeline (URL classification)
â”‚   â”œâ”€â”€ db/                   # Snowflake ORM and table schemas
â”œâ”€â”€ takeout_dbt/              # DBT project for transforming ingested Takeout data
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile                # Docker image configuration
â”œâ”€â”€ .env.example              # Template environment file
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ”¹ Workflow Overview

1. Parse Takeout data using scripts in `src/parsers/` to generate CSVs.
2. Load CSVs into Snowflake for structured storage.
3. Run topic modeling pipeline (`src/topic_modeling/`) to link URLs to topics (optional).
4. Transform and test data with DBT (`takeout_dbt/`) for staging and mart models.
5. Visualize results in Metabase, exploring browsing patterns and trends.

---

## ğŸ’¡ Notes

- The .env file must be correctly configured before running any scripts.
- Parsers support YouTube, Chrome, and phone history exports from Google Takeout.
- Topic modeling output can serve as input to DBT mart models for downstream analysis.